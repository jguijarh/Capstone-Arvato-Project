{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_ML_algorithms_for_supervised_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'm going to implement the diferent algorithms to supervised learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "import h2o\n",
    "from h2o.estimators.xgboost import H2OXGBoostEstimator\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "sys.path.append('..')\n",
    "from utilities.helpers_data_cleaning import (distincts_in_col,\n",
    "                                             convert_categorical,\n",
    "                                             nan_in_col,\n",
    "                                             read_feats,\n",
    "                                             generate_synthetic_train_data,\n",
    "                                             obtain_features_label,\n",
    "                                             fill_categorical,\n",
    "                                             split_data,\n",
    "                                             plot_pca,\n",
    "                                             pca_features,\n",
    "                                             elbow_Kmeans,\n",
    "                                             cast_categorical_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA_GERMANY = Path('../data/german_poblation/')\n",
    "PATH_DATA_CUSTOMER = Path('../data/customers/')\n",
    "PATH_DATA_MAILOUT = Path('../data/mailout/')\n",
    "PATH_FEATS = Path(\"../data/feats/DIAS Attributes - Values 2017.xlsx\")\n",
    "PATH_SAVE = Path(\"../data/data_processed\")\n",
    "PAT_SAVE_PIPELINES = Path(\"../data/pipelines\")\n",
    "pipeline_pca = load(PAT_SAVE_PIPELINES / 'pipeline_pca_full_variables.pkl')\n",
    "pipeline_kmeans = load(PAT_SAVE_PIPELINES / 'pipeline_kmeans_full_variables.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain features from models previously trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Proxy is defined in the environment: HTTP_PROXY. This may interfere with your H2O Connection.\n",
      "Proxy is defined in the environment: http_proxy. This may interfere with your H2O Connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.2\" 2019-01-15; OpenJDK Runtime Environment 18.9 (build 11.0.2+9); OpenJDK 64-Bit Server VM 18.9 (build 11.0.2+9, mixed mode)\n",
      "  Starting server from /home/jguijarh/anaconda3/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpww2ijttx\n",
      "  JVM stdout: /tmp/tmpww2ijttx/h2o_jguijarh_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpww2ijttx/h2o_jguijarh_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Madrid</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 3 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_jguijarh_u2nrif</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>2.746 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         03 secs\n",
       "H2O_cluster_timezone:       Europe/Madrid\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.1\n",
       "H2O_cluster_version_age:    1 month and 3 days\n",
       "H2O_cluster_name:           H2O_from_python_jguijarh_u2nrif\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    2.746 Gb\n",
       "H2O_cluster_total_cores:    5\n",
       "H2O_cluster_allowed_cores:  5\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.6 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "xgb_model = h2o.load_model('../data/models/model_less_features_with_cluster/model_with_cluster')\n",
    "popu_data = h2o.import_file(path='../data/data_processed/synthetic_df_with_clusters_ver_2.csv')\n",
    "nullity_vars = list(xgb_model.actual_params['ignored_columns'])\n",
    "exclude_feats = nullity_vars + ['LNR', 'target_customer']\n",
    "\n",
    "features_with_cluster = [feat for feat in popu_data.columns if feat not in exclude_feats]\n",
    "label_with_cluster = ['target_customer']\n",
    "\n",
    "label_train = label_with_cluster\n",
    "features_train = features_with_cluster\n",
    "\n",
    "h2o.remove_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_b645 closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = read_feats(PATH_FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mailout_train = pd.read_csv(PATH_DATA_MAILOUT /\n",
    "                               'Udacity_MAILOUT_052018_TRAIN.csv',\n",
    "                               dtype= features_dict,\n",
    "                               na_values=[-1,'X','XX'],\n",
    "                               sep=';').drop(columns = ['Unnamed: 0'])\n",
    "df_mailout_train = convert_categorical(df_mailout_train)\n",
    "df_mailout_train = fill_categorical(df_mailout_train)\n",
    "\n",
    "df_mailout_test = pd.read_csv(PATH_DATA_MAILOUT /\n",
    "                              'Udacity_MAILOUT_052018_TEST.csv',\n",
    "                              dtype= features_dict,\n",
    "                              na_values=[-1,'X','XX'],\n",
    "                              sep=';').drop(columns = ['Unnamed: 0'])\n",
    "df_mailout_test = convert_categorical(df_mailout_test)\n",
    "df_mailout_test = fill_categorical(df_mailout_test)\n",
    "df_mailout_train = df_mailout_train.rename(columns={'RESPONSE': label_train[0]})\n",
    "\n",
    "features, label = obtain_features_label(df_mailout_train)\n",
    "\n",
    "# Obtain the clusters\n",
    "X_mailout_train = (df_mailout_train[features]\n",
    "                   .select_dtypes(include='number')\n",
    "                   .reset_index(drop=True).copy())\n",
    "df_mailout_train['CLUSTER'] = pipeline_kmeans.predict(X_mailout_train)\n",
    "\n",
    "X_mailout_test = (df_mailout_test[features]\n",
    "                     .select_dtypes(include='number')\n",
    "                     .reset_index(drop=True).copy())\n",
    "df_mailout_test['CLUSTER'] = pipeline_kmeans.predict(X_mailout_test)\n",
    "\n",
    "# Predict the cluster and insert the new feat in the dictionary\n",
    "df_mailout_train['CLUSTER'] = df_mailout_train['CLUSTER'].astype('category')\n",
    "df_mailout_test['CLUSTER'] = df_mailout_test['CLUSTER'].astype('category')\n",
    "features_dict['CLUSTER'] = 'category'\n",
    "cat_feats = df_mailout_train.select_dtypes(include='category').columns\n",
    "\n",
    "#save the processed data\n",
    "df_mailout_train.to_csv(PATH_SAVE / 'df_mailout_train_processed.csv', index=False)\n",
    "df_mailout_test.to_csv(PATH_SAVE / 'df_mailout_test_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I just going to train the model with mail train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mailout_train[features_train]\n",
    "y = df_mailout_train[label_train[0]]\n",
    "\n",
    "cat_feats = X.select_dtypes(include=['category','object']).columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=1993,\n",
    "        stratify=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pipeline to train the model\n",
    "In this pipeline I do three main steps:\n",
    "    - An oversample of the data, to increase the ratio that positive cases have in the data\n",
    "    - A weights of evidence to encode the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgb = {\n",
    "    \"ntrees\" : 40,\n",
    "    \"max_depth\" : 8,\n",
    "    \"learn_rate\" : 0.01,\n",
    "    \"sample_rate\" : 0.8,\n",
    "    \"col_sample_rate_per_tree\" : 0.8,\n",
    "    \"min_rows\" : 3,\n",
    "    \"random_state\": 1993,\n",
    "    \"stopping_metric\": 'AUC',\n",
    "    \"n_jobs\":-1,\n",
    "#     \"reg_alpha\":0.1\n",
    "    }\n",
    "    \n",
    "pipeline_encoder_and_xgb = make_pipeline(\n",
    "    RandomOverSampler(sampling_strategy=.02, random_state=1993),\n",
    "    WOEEncoder(cols=cat_feats),\n",
    "    XGBClassifier(**param_xgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('randomoversampler',\n",
       "                 RandomOverSampler(random_state=1993, sampling_strategy=0.02)),\n",
       "                ('woeencoder',\n",
       "                 WOEEncoder(cols=Index(['ALTER_HH', 'BALLRAUM', 'CAMEO_DEU_2015', 'CAMEO_DEUG_2015',\n",
       "       'CJT_GESAMTTYP', 'D19_BANKEN_DATUM', 'D19_BANKEN_OFFLINE_DATUM',\n",
       "       'D19_BANKEN_ONLINE_DATUM', 'D19_GESAMT_DATUM',\n",
       "       'D19_GESAMT_OFFLINE_DATUM',\n",
       "       ...\n",
       "       'SEMIO_TR...\n",
       "                               interaction_constraints=None, learn_rate=0.01,\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=8, min_child_weight=1, min_rows=3,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               n_estimators=100, n_jobs=-1, ntrees=40,\n",
       "                               num_parallel_tree=1, objective='binary:logistic',\n",
       "                               random_state=1993, reg_alpha=0, reg_lambda=1,\n",
       "                               sample_rate=0.8, scale_pos_weight=1,\n",
       "                               stopping_metric='AUC', subsample=1, ...))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_encoder_and_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6812750243991366"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_xgb = roc_auc_score(\n",
    "    y_test, pipeline_encoder_and_xgb.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "auc_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle_submission_xgb = pd.DataFrame(dict(LNR=df_mailout_test['LNR'],\n",
    "                                                  RESPONSE=pipeline_encoder_and_xgb.predict_proba(df_mailout_test[features_train])[:,1]))\n",
    "\n",
    "df_kaggle_submission_xgb.to_csv('../data/kaggle_competition/prediction_xgboost_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "# CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pipeline\n",
    "In this pipeline, I define two main steps:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('randomoversampler',\n",
       "                 RandomOverSampler(random_state=1993, sampling_strategy=0.02)),\n",
       "                ('catboostclassifier',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x7fa10f2e95d0>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_catboost = dict(num_trees=15,\n",
    "                       max_depth=3,\n",
    "                       min_child_samples=25,\n",
    "                       one_hot_max_size=4,\n",
    "                       cat_features=cat_feats,\n",
    "                       random_state=1993,\n",
    "                       eval_metric='AUC',\n",
    "                       verbose=0)\n",
    "\n",
    "pipeline_encoder_catboost = make_pipeline(\n",
    "    RandomOverSampler(sampling_strategy=.02, random_state=1993),\n",
    "    CatBoostClassifier(**params_catboost)\n",
    ")\n",
    "\n",
    "pipeline_encoder_catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7812842504963196"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_catboost_oversampling = roc_auc_score(\n",
    "    y_test, \n",
    "    pipeline_encoder_catboost.predict_proba(X_test)[:, 1])\n",
    "auc_catboost_oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle_submission_catboost = pd.DataFrame(dict(LNR=df_mailout_test['LNR'],\n",
    "                                                  RESPONSE=pipeline_encoder_catboost.predict_proba(df_mailout_test[features_train])[:,1]))\n",
    "\n",
    "df_kaggle_submission_catboost.to_csv('../data/kaggle_competition/prediction_catboost_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp_cat = dict(zip(pipeline_encoder_catboost.steps[-1][1].feature_names_,\n",
    "    pipeline_encoder_catboost.steps[-1][1].feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the lightgbm pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {\n",
    "    \"ntrees\" : 40,\n",
    "    \"max_depth\" : 8,\n",
    "    \"learn_rate\" : 0.01,\n",
    "    \"sample_rate\" : 0.8,\n",
    "    \"col_sample_rate_per_tree\" : 0.8,\n",
    "    \"min_rows\" : 3,\n",
    "    \"random_state\": 1993,\n",
    "    \"stopping_metric\": 'AUC',\n",
    "    \"n_jobs\":-1\n",
    "#     \"reg_alpha\":0.1\n",
    "    }\n",
    "    \n",
    "pipeline_encoder_and_lgb = make_pipeline(\n",
    "    WOEEncoder(cols=cat_feats),\n",
    "    lgb.LGBMClassifier(**param_lgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_encoder_and_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6969944043164795"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_lgb = roc_auc_score(\n",
    "    y_test, pipeline_encoder_and_lgb.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "auc_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle_submission_lgboost = pd.DataFrame(dict(LNR=df_mailout_test['LNR'],\n",
    "                                                  RESPONSE=pipeline_encoder_and_lgb.predict_proba(df_mailout_test[features_train])[:,1]))\n",
    "\n",
    "df_kaggle_submission_lgboost.to_csv('../data/kaggle_competition/prediction_lgboost_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Population data mixed with mailout campaign train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the data that I'm going to use in this section. Te data will be:\n",
    "- 15% of population data that i have used in the first section of this project.\n",
    "- MAILOUT train data.\n",
    "\n",
    "I read the data that contein population data and get a sample of 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = (pd.read_csv('../data/data_processed/synthetic_df_with_clusters_ver_2.csv',\n",
    "                             dtype= features_dict)\n",
    "                 .sample(frac=0.15)\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "# df_population = (pd.read_csv('../data/data_processed/synthetic_df_with_clusters_ver_2.csv',\n",
    "#                              dtype= features_dict)\n",
    "#                  .sample(frac=0.20)\n",
    "#                  .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data set to future data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_composed = pd.concat([df_population, df_mailout_train]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_composed = df_train_composed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_composed[features_train]\n",
    "y = df_train_composed[label_train[0]]\n",
    "\n",
    "cat_feats = X.select_dtypes(include=['category','object']).columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=1993,\n",
    "        stratify=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost mixed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the XGBoost and the pipeline to the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a8ef06d3804b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m pipeline_encoder_and_xgb_mixed = make_pipeline(\n\u001b[1;32m     15\u001b[0m     \u001b[0mWOEEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "param_xgb = {\n",
    "    \"ntrees\" : 40,\n",
    "    \"max_depth\" : 8,\n",
    "    \"learn_rate\" : 0.01,\n",
    "    \"sample_rate\" : 0.8,\n",
    "    \"col_sample_rate_per_tree\" : 0.8,\n",
    "    \"min_rows\" : 3,\n",
    "    \"random_state\": 1993,\n",
    "    \"stopping_metric\": 'AUC',\n",
    "    \"n_jobs\":-1,\n",
    "#     \"reg_alpha\":0.1\n",
    "    }\n",
    "    \n",
    "pipeline_encoder_and_xgb_mixed = make_pipeline(\n",
    "    WOEEncoder(cols=cat_feats),\n",
    "    XGBClassifier(**param_xgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_encoder_and_xgb_mixed.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9537283622549791"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_xgb = roc_auc_score(\n",
    "    y_test, pipeline_encoder_and_xgb_mixed.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "auc_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle_submission_xgb = pd.DataFrame(dict(LNR=df_mailout_test['LNR'],\n",
    "                                                  RESPONSE=pipeline_encoder_and_xgb_mixed.predict_proba(df_mailout_test[features_train])[:,1]))\n",
    "\n",
    "df_kaggle_submission_xgb.to_csv('../data/kaggle_competition/prediction_xgboost_mixed_data_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lgb = cross_val_score_catboost_oversampling = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "# CatBoost with mixed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pipeline\n",
    "In this pipeline, I define two main steps:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('catboostclassifier',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x7f27636ddcd0>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_catboost = dict(num_trees=40,\n",
    "                       max_depth=4,\n",
    "                       min_child_samples=25,\n",
    "                       one_hot_max_size=4,\n",
    "                       cat_features=cat_feats,\n",
    "                       random_state=1993,\n",
    "                       eval_metric='AUC',\n",
    "                       verbose=0)\n",
    "\n",
    "\n",
    "pipeline_encoder_catboost_mixed = make_pipeline(\n",
    "    CatBoostClassifier(**params_catboost)\n",
    ")\n",
    "\n",
    "pipeline_encoder_catboost_mixed.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92073899054021"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_catboost_oversampling_mixed = roc_auc_score(\n",
    "    y_test, \n",
    "    pipeline_encoder_catboost_mixed.predict_proba(X_test)[:, 1])\n",
    "auc_catboost_oversampling_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle_submission_catboost_mixed = pd.DataFrame(dict(LNR=df_mailout_test['LNR'],\n",
    "                                                  RESPONSE=pipeline_encoder_catboost_mixed.predict_proba(df_mailout_test[features_train])[:,1]))\n",
    "\n",
    "df_kaggle_submission_catboost_mixed.to_csv('../data/kaggle_competition/prediction_catboost_mixed_data_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the importance of variables inside the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp_cat = dict(zip(pipeline_encoder_catboost.steps[-1][1].feature_names_,\n",
    "                      pipeline_encoder_catboost.steps[-1][1].feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM with mixed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the lightgbm pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = { \n",
    "    \"ntrees\" : 50,\n",
    "    \"max_depth\" : 8,\n",
    "    \"learn_rate\" : 0.01,\n",
    "    \"sample_rate\" : 0.8,\n",
    "    \"col_sample_rate_per_tree\" : 0.8,\n",
    "    \"min_rows\" : 3,\n",
    "    \"random_state\": 1993,\n",
    "    \"stopping_metric\": 'AUC',\n",
    "    \"n_jobs\":-1\n",
    "    }\n",
    "\n",
    "pipeline_encoder_and_lgb_mixed = make_pipeline(\n",
    "    WOEEncoder(cols=cat_feats),\n",
    "    lgb.LGBMClassifier(**param_lgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('woeencoder',\n",
       "                 WOEEncoder(cols=Index(['ALTER_HH', 'BALLRAUM', 'CAMEO_DEU_2015', 'CAMEO_DEUG_2015',\n",
       "       'CJT_GESAMTTYP', 'D19_BANKEN_DATUM', 'D19_BANKEN_OFFLINE_DATUM',\n",
       "       'D19_BANKEN_ONLINE_DATUM', 'D19_GESAMT_DATUM',\n",
       "       'D19_GESAMT_OFFLINE_DATUM',\n",
       "       ...\n",
       "       'SEMIO_TRADV', 'SEMIO_VERT', 'VERS_TYP', 'W_KEIT_KIND_HH',\n",
       "       'WOHNDAUER_2008', 'WOHNLAGE', 'ZABEOTY...\n",
       "                                learn_rate=0.01, learning_rate=0.1,\n",
       "                                max_depth=15, min_child_samples=20,\n",
       "                                min_child_weight=0.001, min_rows=3,\n",
       "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                ntrees=80, num_leaves=31, objective=None,\n",
       "                                random_state=1993, reg_alpha=0.0,\n",
       "                                reg_lambda=0.0, sample_rate=0.8, silent=True,\n",
       "                                stopping_metric='AUC', subsample=1.0,\n",
       "                                subsample_for_bin=200000, subsample_freq=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_encoder_and_lgb_mixed.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609141525552982"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_lgb = roc_auc_score(\n",
    "    y_test, pipeline_encoder_and_lgb_mixed.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "auc_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save teh data to submit on kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle_submission_lgboost = pd.DataFrame(dict(LNR=df_mailout_test['LNR'],\n",
    "                                                  RESPONSE=pipeline_encoder_and_lgb_mixed.predict_proba(df_mailout_test[features_train])[:,1]))\n",
    "\n",
    "df_kaggle_submission_lgboost.to_csv('../data/kaggle_competition/prediction_lgboost_mixed_8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
